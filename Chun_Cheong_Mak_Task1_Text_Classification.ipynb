{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some categories from the training set\n",
    "categories = ['alt.atheism', 'talk.religion.misc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset for categories:\n",
      "['alt.atheism', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857 documents\n",
      "2 categories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "print(f\"{len(Train.filenames)} documents\")\n",
    "print(f\"{len(Train.target_names)} categories\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train = Train.data\n",
    "y_Train = Train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570 documents\n",
      "2 categories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "print(f\"{len(Test.filenames)} documents\")\n",
    "print(f\"{len(Test.target_names)} categories\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Test = Test.data\n",
    "y_Test = Test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_mnb = Pipeline([('vect', CountVectorizer()), \n",
    "                    ('mnb', MultinomialNB())])\n",
    "vect_log = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('lr', LogisticRegression())])\n",
    "vect_svc = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('svc', SVC())])\n",
    "vect_tree = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tree', DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_mnb_para = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'mnb__alpha': np.linspace(0.5, 1.5, 6),\n",
    "    'mnb__fit_prior': [True, False]\n",
    "    }\n",
    "vect_log_para = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'lr__penalty': ['l1', 'l2'],\n",
    "    'lr__C': [1, 5, 10],\n",
    "    'lr__max_iter': [20, 50, 100]\n",
    "    }\n",
    "vect_svc_para = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'svc__C': [0.1, 1, 10, 100], \n",
    "    'svc__gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'svc__kernel': ['rbf', 'poly']\n",
    "    }\n",
    "vect_tree_para = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'tree__max_depth': [2, 3, 5, 10, 20],\n",
    "    'tree__min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'tree__criterion': [\"gini\", \"entropy\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_mnb_model = GridSearchCV(vect_mnb, vect_mnb_para, cv=5, n_jobs=-1, verbose=1)\n",
    "vect_log_model = GridSearchCV(vect_log, vect_log_para, cv=5, n_jobs=-1, verbose=1)\n",
    "vect_svc_model = GridSearchCV(vect_svc, vect_svc_para, cv=5, n_jobs=-1, verbose=1)\n",
    "vect_tree_model = GridSearchCV(vect_tree, vect_tree_para, cv=5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2160 out of 2160 | elapsed:  6.7min finished\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 768 candidates, totalling 3840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3840 out of 3840 | elapsed: 23.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1200 candidates, totalling 6000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6000 out of 6000 | elapsed: 13.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                                       ('tree', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'tree__criterion': ['gini', 'entropy'],\n",
       "                         'tree__max_depth': [2, 3, 5, 10, 20],\n",
       "                         'tree__min_samples_leaf': [5, 10, 20, 50, 100],\n",
       "                         'vect__max_df': (0.5, 0.75, 1.0),\n",
       "                         'vect__max_features': (None, 5000, 10000, 50000),\n",
       "                         'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_mnb_model.fit(X_Train, y_Train)\n",
    "vect_log_model.fit(X_Train, y_Train)\n",
    "vect_svc_model.fit(X_Train, y_Train)\n",
    "vect_tree_model.fit(X_Train, y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (Multinomial Naïve Bayes & CountVectorizer): 0.947\n",
      "Best score (Logistic Regression & CountVectorizer): 0.956\n",
      "Best score (Support Vector Machines & CountVectorizer): 0.937\n",
      "Best score (Decision Trees & CountVectorizer): 0.873\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score (Multinomial Naïve Bayes & CountVectorizer): %0.3f\" % vect_mnb_model.best_score_)\n",
    "print(\"Best score (Logistic Regression & CountVectorizer): %0.3f\" % vect_log_model.best_score_)\n",
    "print(\"Best score (Support Vector Machines & CountVectorizer): %0.3f\" % vect_svc_model.best_score_)\n",
    "print(\"Best score (Decision Trees & CountVectorizer): %0.3f\" % vect_tree_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_vect_mnb_model = vect_mnb_model.predict(X_Test)\n",
    "y_pred_vect_log_model = vect_log_model.predict(X_Test)\n",
    "y_pred_vect_svc_model = vect_svc_model.predict(X_Test)\n",
    "y_pred_vect_tree_model = vect_tree_model.predict(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (Multinomial Naïve Bayes & CountVectorizer): 0.865\n",
      "Accuracy score (Logistic Regression & CountVectorizer): 0.811\n",
      "Accuracy score (Support Vector Machines & CountVectorizer): 0.802\n",
      "Accuracy score (Decision Trees & CountVectorizer): 0.791\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score (Multinomial Naïve Bayes & CountVectorizer): %0.3f\" % accuracy_score(y_Test, y_pred_vect_mnb_model))\n",
    "print(\"Accuracy score (Logistic Regression & CountVectorizer): %0.3f\" % accuracy_score(y_Test, y_pred_vect_log_model))\n",
    "print(\"Accuracy score (Support Vector Machines & CountVectorizer): %0.3f\" % accuracy_score(y_Test, y_pred_vect_svc_model))\n",
    "print(\"Accuracy score (Decision Trees & CountVectorizer): %0.3f\" % accuracy_score(y_Test, y_pred_vect_tree_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set (Multinomial Naïve Bayes & CountVectorizer):\n",
      "\tmnb__alpha: 0.5\n",
      "\tmnb__fit_prior: True\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 50000\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set (Multinomial Naïve Bayes & CountVectorizer):\")\n",
    "best_parameters = vect_mnb_model.best_estimator_.get_params()\n",
    "for param_name in sorted(vect_mnb_para.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set (Logistic Regression & CountVectorizer):\n",
      "\tlr__C: 10\n",
      "\tlr__max_iter: 50\n",
      "\tlr__penalty: 'l2'\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__max_features: None\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set (Logistic Regression & CountVectorizer):\")\n",
    "best_parameters = vect_log_model.best_estimator_.get_params()\n",
    "for param_name in sorted(vect_log_para.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set (Support Vector Machines & CountVectorizer):\n",
      "\tsvc__C: 100\n",
      "\tsvc__gamma: 0.001\n",
      "\tsvc__kernel: 'rbf'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 10000\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set (Support Vector Machines & CountVectorizer):\")\n",
    "best_parameters = vect_svc_model.best_estimator_.get_params()\n",
    "for param_name in sorted(vect_svc_para.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set (Decision Trees & CountVectorizer):\n",
      "\ttree__criterion: 'gini'\n",
      "\ttree__max_depth: 20\n",
      "\ttree__min_samples_leaf: 5\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 5000\n",
      "\tvect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set (Decision Trees & CountVectorizer):\")\n",
    "best_parameters = vect_tree_model.best_estimator_.get_params()\n",
    "for param_name in sorted(vect_tree_para.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_mnb = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()), \n",
    "                     ('mnb', MultinomialNB())])\n",
    "tfidf_log = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('lr', LogisticRegression())])\n",
    "tfidf_svc = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('svc', SVC())])\n",
    "tfidf_tree = Pipeline([('vect', CountVectorizer()),\n",
    "                       ('tfidf', TfidfTransformer()),\n",
    "                       ('tree', DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_mnb_para = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'mnb__alpha': np.linspace(0.5, 1.5, 6),\n",
    "    'mnb__fit_prior': [True, False]\n",
    "    }\n",
    "tfidf_log_para = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'lr__penalty': ['l1', 'l2'],\n",
    "    'lr__C': [1, 5, 10],\n",
    "    'lr__max_iter': [20, 50, 100]\n",
    "    }\n",
    "tfidf_svc_para = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'svc__C': [0.1, 1, 10, 100], \n",
    "    'svc__gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'svc__kernel': ['rbf', 'poly']\n",
    "    }\n",
    "tfidf_tree_para = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'tree__max_depth': [2, 3, 5, 10, 20],\n",
    "    'tree__min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'tree__criterion': [\"gini\", \"entropy\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_mnb_model = GridSearchCV(tfidf_mnb, tfidf_mnb_para, cv=5, n_jobs=-1, verbose=1)\n",
    "tfidf_log_model = GridSearchCV(tfidf_log, tfidf_log_para, cv=5, n_jobs=-1, verbose=1)\n",
    "tfidf_svc_model = GridSearchCV(tfidf_svc, tfidf_svc_para, cv=5, n_jobs=-1, verbose=1)\n",
    "tfidf_tree_model = GridSearchCV(tfidf_tree, tfidf_tree_para, cv=5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1152 candidates, totalling 5760 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   57.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5760 out of 5760 | elapsed: 12.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1728 candidates, totalling 8640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   46.7s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed: 15.3min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=-1)]: Done 8640 out of 8640 | elapsed: 18.8min finished\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3072 candidates, totalling 15360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   52.1s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 18.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 23.4min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed: 28.2min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed: 33.6min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed: 39.4min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed: 45.9min\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed: 52.8min\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed: 60.1min\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed: 67.8min\n",
      "[Parallel(n_jobs=-1)]: Done 15360 out of 15360 | elapsed: 72.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4800 candidates, totalling 24000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed: 19.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed: 22.8min\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed: 26.2min\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed: 29.8min\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed: 33.7min\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed: 37.8min\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed: 42.3min\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed: 46.7min\n",
      "[Parallel(n_jobs=-1)]: Done 22034 tasks      | elapsed: 51.4min\n",
      "[Parallel(n_jobs=-1)]: Done 24000 out of 24000 | elapsed: 56.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('tree', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'tfidf__norm': ('l1', 'l2'),\n",
       "                         'tfidf__use_idf': (True, False),\n",
       "                         'tree__criterion': ['gini', 'entropy'],\n",
       "                         'tree__max_depth': [2, 3, 5, 10, 20],\n",
       "                         'tree__min_samples_leaf': [5, 10, 20, 50, 100],\n",
       "                         'vect__max_df': (0.5, 0.75, 1.0),\n",
       "                         'vect__max_features': (None, 5000, 10000, 50000),\n",
       "                         'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_mnb_model.fit(X_Train, y_Train)\n",
    "tfidf_log_model.fit(X_Train, y_Train)\n",
    "tfidf_svc_model.fit(X_Train, y_Train)\n",
    "tfidf_tree_model.fit(X_Train, y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (Multinomial Naïve Bayes & TFIDF): 0.935\n",
      "Best score (Logistic Regression & TFIDF): 0.954\n",
      "Best score (Support Vector Machines & TFIDF): 0.959\n",
      "Best score (Decision Trees & TFIDF): 0.876\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score (Multinomial Naïve Bayes & TFIDF): %0.3f\" % tfidf_mnb_model.best_score_)\n",
    "print(\"Best score (Logistic Regression & TFIDF): %0.3f\" % tfidf_log_model.best_score_)\n",
    "print(\"Best score (Support Vector Machines & TFIDF): %0.3f\" % tfidf_svc_model.best_score_)\n",
    "print(\"Best score (Decision Trees & TFIDF): %0.3f\" % tfidf_tree_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tfidf_mnb_model = tfidf_mnb_model.predict(X_Test)\n",
    "y_pred_tfidf_log_model = tfidf_log_model.predict(X_Test)\n",
    "y_pred_tfidf_svc_model = tfidf_svc_model.predict(X_Test)\n",
    "y_pred_tfidf_tree_model = tfidf_tree_model.predict(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### The Accuracy Score on Test Set ####\n",
      "-------------------------------------------\n",
      "Accuracy score (Multinomial Naïve Bayes & TFIDF): 0.851\n",
      "Accuracy score (Logistic Regression & TFIDF): 0.863\n",
      "Accuracy score (Support Vector Machines & TFIDF): 0.847\n",
      "Accuracy score (Decision Trees & TFIDF): 0.765\n"
     ]
    }
   ],
   "source": [
    "print(\"#### The Accuracy Score on Test Set ####\")\n",
    "print('-------------------------------------------')\n",
    "print(\"Accuracy score (Multinomial Naïve Bayes & TFIDF): %0.3f\" % accuracy_score(y_Test, y_pred_tfidf_mnb_model))\n",
    "print(\"Accuracy score (Logistic Regression & TFIDF): %0.3f\" % accuracy_score(y_Test, y_pred_tfidf_log_model))\n",
    "print(\"Accuracy score (Support Vector Machines & TFIDF): %0.3f\" % accuracy_score(y_Test, y_pred_tfidf_svc_model))\n",
    "print(\"Accuracy score (Decision Trees & TFIDF): %0.3f\" % accuracy_score(y_Test, y_pred_tfidf_tree_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set (Multinomial Naïve Bayes & TFIDF):\n",
      "\tmnb__alpha: 0.5\n",
      "\tmnb__fit_prior: False\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 10000\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set (Multinomial Naïve Bayes & TFIDF):\")\n",
    "best_parameters = tfidf_mnb_model.best_estimator_.get_params()\n",
    "for param_name in sorted(tfidf_mnb_para.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set (Logistic Regression & TFIDF):\n",
      "\tlr__C: 10\n",
      "\tlr__max_iter: 20\n",
      "\tlr__penalty: 'l2'\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__max_features: 50000\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set (Logistic Regression & TFIDF):\")\n",
    "best_parameters = tfidf_log_model.best_estimator_.get_params()\n",
    "for param_name in sorted(tfidf_log_para.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set (Support Vector Machines & TFIDF):\n",
      "\tsvc__C: 10\n",
      "\tsvc__gamma: 0.1\n",
      "\tsvc__kernel: 'rbf'\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 10000\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set (Support Vector Machines & TFIDF):\")\n",
    "best_parameters = tfidf_svc_model.best_estimator_.get_params()\n",
    "for param_name in sorted(tfidf_svc_para.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set (Decision Trees & TFIDF):\n",
      "\ttfidf__norm: 'l1'\n",
      "\ttfidf__use_idf: True\n",
      "\ttree__criterion: 'gini'\n",
      "\ttree__max_depth: 20\n",
      "\ttree__min_samples_leaf: 5\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 5000\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set (Decision Trees & TFIDF):\")\n",
    "best_parameters = tfidf_tree_model.best_estimator_.get_params()\n",
    "for param_name in sorted(tfidf_tree_para.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/ccmakad/Desktop/Applied AI/SEM 1/AASD 4004 Machine Learning II/Module 03 - Text Classification/GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = KeyedVectors.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_feats(list_of_lists):\n",
    "    DIMENSION = 300\n",
    "    # one dimensional zero vector\n",
    "    zero_vector = np.zeros(DIMENSION)\n",
    "    feats = []\n",
    "    # tokens: one document \n",
    "    for tokens in list_of_lists:\n",
    "        feat_for_this = np.zeros(DIMENSION)\n",
    "        count_for_this = 0\n",
    "        # a particular token in one document\n",
    "        for token in tokens:\n",
    "            if token in w2v_model:\n",
    "                # Sum of the token vectors \n",
    "                feat_for_this += w2v_model[token]\n",
    "                # Number of token vectors in one document\n",
    "                count_for_this += 1\n",
    "        feats.append(feat_for_this/count_for_this)\n",
    "    return feats     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df = pd.DataFrame(Train.data, columns=['text'])\n",
    "Train_df['text_clean'] = Train_df['text'].apply(lambda x: gensim.utils.simple_preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: mangoe@cs.umd.edu (Charley Wingate)\\nSub...</td>\n",
       "      <td>[from, mangoe, cs, umd, edu, charley, wingate,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: Re: There must be a creator! (Maybe)\\...</td>\n",
       "      <td>[subject, re, there, must, be, creator, maybe,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: MANDTBACKA@FINABO.ABO.FI (Mats Andtbacka...</td>\n",
       "      <td>[from, mandtbacka, finabo, abo, fi, mats, andt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: royc@rbdc.wsnc.org (Roy Crabtree)\\nSubje...</td>\n",
       "      <td>[from, royc, rbdc, wsnc, org, roy, crabtree, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: Re: \"Imaginary\" Friends - Info and Ex...</td>\n",
       "      <td>[subject, re, imaginary, friends, info, and, e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  From: mangoe@cs.umd.edu (Charley Wingate)\\nSub...   \n",
       "1  Subject: Re: There must be a creator! (Maybe)\\...   \n",
       "2  From: MANDTBACKA@FINABO.ABO.FI (Mats Andtbacka...   \n",
       "3  From: royc@rbdc.wsnc.org (Roy Crabtree)\\nSubje...   \n",
       "4  Subject: Re: \"Imaginary\" Friends - Info and Ex...   \n",
       "\n",
       "                                          text_clean  \n",
       "0  [from, mangoe, cs, umd, edu, charley, wingate,...  \n",
       "1  [subject, re, there, must, be, creator, maybe,...  \n",
       "2  [from, mandtbacka, finabo, abo, fi, mats, andt...  \n",
       "3  [from, royc, rbdc, wsnc, org, roy, crabtree, s...  \n",
       "4  [subject, re, imaginary, friends, info, and, e...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_train_documents = [i for i in Train_df['text_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_w2v = embedding_feats(list_of_train_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 857 documents and the dimension of each document is 300.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(Train_w2v)} documents and the dimension of each document is {len(Train_w2v[0])}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_df = pd.DataFrame(Test.data, columns=['text'])\n",
    "Test_df['text_clean'] = Test_df['text'].apply(lambda x: gensim.utils.simple_preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: livesey@solntze.wpd.sgi.com (Jon Livesey...</td>\n",
       "      <td>[from, livesey, solntze, wpd, sgi, com, jon, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: aiken@unity.ncsu.edu (Wayne NMI Aiken)\\n...</td>\n",
       "      <td>[from, aiken, unity, ncsu, edu, wayne, nmi, ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: bil@okcforum.osrhe.edu (Bill Conner)\\nSu...</td>\n",
       "      <td>[from, bil, okcforum, osrhe, edu, bill, conner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: Re: [rw] Is Robert Weiss the only ort...</td>\n",
       "      <td>[subject, re, rw, is, robert, weiss, the, only...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jaeger@buphy.bu.edu (Gregg Jaeger)\\nSubj...</td>\n",
       "      <td>[from, jaeger, buphy, bu, edu, gregg, jaeger, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  From: livesey@solntze.wpd.sgi.com (Jon Livesey...   \n",
       "1  From: aiken@unity.ncsu.edu (Wayne NMI Aiken)\\n...   \n",
       "2  From: bil@okcforum.osrhe.edu (Bill Conner)\\nSu...   \n",
       "3  Subject: Re: [rw] Is Robert Weiss the only ort...   \n",
       "4  From: jaeger@buphy.bu.edu (Gregg Jaeger)\\nSubj...   \n",
       "\n",
       "                                          text_clean  \n",
       "0  [from, livesey, solntze, wpd, sgi, com, jon, l...  \n",
       "1  [from, aiken, unity, ncsu, edu, wayne, nmi, ai...  \n",
       "2  [from, bil, okcforum, osrhe, edu, bill, conner...  \n",
       "3  [subject, re, rw, is, robert, weiss, the, only...  \n",
       "4  [from, jaeger, buphy, bu, edu, gregg, jaeger, ...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_test_documents = [i for i in Test_df['text_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_w2v = embedding_feats(list_of_test_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 570 documents and the dimension of each document is 300.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(Test_w2v)} documents and the dimension of each document is {len(Test_w2v[0])}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_mnb = Pipeline([('minmax',MinMaxScaler()), ('mnb', MultinomialNB())])\n",
    "w2v_log = Pipeline([('lr', LogisticRegression())])\n",
    "w2v_svc = Pipeline([('svc', SVC())])\n",
    "w2v_tree = Pipeline([('tree', DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_para = {\n",
    "    'mnb__alpha': np.linspace(0.5, 1.5, 6),\n",
    "    'mnb__fit_prior': [True, False]\n",
    "    }\n",
    "log_para = {\n",
    "    'lr__penalty': ['l1', 'l2'],\n",
    "    'lr__C': [1, 5, 10],\n",
    "    'lr__max_iter': [20, 50, 100]\n",
    "    }\n",
    "svc_para = {\n",
    "    'svc__C': [0.1, 1, 10, 100], \n",
    "    'svc__gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'svc__kernel': ['rbf', 'poly']\n",
    "    }\n",
    "tree_para = {\n",
    "    'tree__max_depth': [2, 3, 5, 10, 20],\n",
    "    'tree__min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'tree__criterion': [\"gini\", \"entropy\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_mnb_model = GridSearchCV(w2v_mnb, mnb_para, cv=5, n_jobs=-1, verbose=1)\n",
    "w2v_log_model = GridSearchCV(w2v_log, log_para, cv=5, n_jobs=-1, verbose=1)\n",
    "w2v_svc_model = GridSearchCV(w2v_svc, svc_para, cv=5, n_jobs=-1, verbose=1)\n",
    "w2v_tree_model = GridSearchCV(w2v_tree, tree_para, cv=5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    1.5s finished\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 235 out of 250 | elapsed:    5.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tree', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'tree__criterion': ['gini', 'entropy'],\n",
       "                         'tree__max_depth': [2, 3, 5, 10, 20],\n",
       "                         'tree__min_samples_leaf': [5, 10, 20, 50, 100]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_mnb_model.fit(Train_w2v, y_Train)\n",
    "w2v_log_model.fit(Train_w2v, y_Train)\n",
    "w2v_svc_model.fit(Train_w2v, y_Train)\n",
    "w2v_tree_model.fit(Train_w2v, y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (Multinomial Naïve Bayes & Word2Vec): 0.692\n",
      "Best score (Logistic Regression & Word2Vec): 0.825\n",
      "Best score (Support Vector Machines & Word2Vec): 0.869\n",
      "Best score (Decision Trees & Word2Vec): 0.679\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score (Multinomial Naïve Bayes & Word2Vec): %0.3f\" % w2v_mnb_model.best_score_)\n",
    "print(\"Best score (Logistic Regression & Word2Vec): %0.3f\" % w2v_log_model.best_score_)\n",
    "print(\"Best score (Support Vector Machines & Word2Vec): %0.3f\" % w2v_svc_model.best_score_)\n",
    "print(\"Best score (Decision Trees & Word2Vec): %0.3f\" % w2v_tree_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_w2v_mnb_model = w2v_mnb_model.predict(Test_w2v)\n",
    "y_pred_w2v_log_model = w2v_log_model.predict(Test_w2v)\n",
    "y_pred_w2v_svc_model = w2v_svc_model.predict(Test_w2v)\n",
    "y_pred_w2v_tree_model = w2v_tree_model.predict(Test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### The Accuracy Score on Test Set ####\n",
      "-------------------------------------------\n",
      "Accuracy score (Multinomial Naïve Bayes & Word2Vec): 0.605\n",
      "Accuracy score (Logistic Regression & Word2Vec): 0.728\n",
      "Accuracy score (Support Vector Machines & Word2Vec): 0.751\n",
      "Accuracy score (Decision Trees & Word2Vec): 0.560\n"
     ]
    }
   ],
   "source": [
    "print(\"#### The Accuracy Score on Test Set ####\")\n",
    "print('-------------------------------------------')\n",
    "print(\"Accuracy score (Multinomial Naïve Bayes & Word2Vec): %0.3f\" % accuracy_score(y_Test, y_pred_w2v_mnb_model))\n",
    "print(\"Accuracy score (Logistic Regression & Word2Vec): %0.3f\" % accuracy_score(y_Test, y_pred_w2v_log_model))\n",
    "print(\"Accuracy score (Support Vector Machines & Word2Vec): %0.3f\" % accuracy_score(y_Test, y_pred_w2v_svc_model))\n",
    "print(\"Accuracy score (Decision Trees & Word2Vec): %0.3f\" % accuracy_score(y_Test, y_pred_w2v_tree_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set (Multinomial Naïve Bayes & Word2Vec):\n",
      "\tmnb__alpha: 1.1\n",
      "\tmnb__fit_prior: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set (Multinomial Naïve Bayes & Word2Vec):\")\n",
    "best_parameters = w2v_mnb_model.best_estimator_.get_params()\n",
    "for param_name in sorted(mnb_para.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set (Logistic Regression & Word2Vec):\n",
      "\tlr__C: 10\n",
      "\tlr__max_iter: 50\n",
      "\tlr__penalty: 'l2'\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set (Logistic Regression & Word2Vec):\")\n",
    "best_parameters = w2v_log_model.best_estimator_.get_params()\n",
    "for param_name in sorted(log_para.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set (Support Vector Machines & Word2Vec):\n",
      "\tsvc__C: 100\n",
      "\tsvc__gamma: 1\n",
      "\tsvc__kernel: 'poly'\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set (Support Vector Machines & Word2Vec):\")\n",
    "best_parameters = w2v_svc_model.best_estimator_.get_params()\n",
    "for param_name in sorted(svc_para.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set (Decision Trees & Word2Vec):\n",
      "\ttree__criterion: 'entropy'\n",
      "\ttree__max_depth: 20\n",
      "\ttree__min_samples_leaf: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set (Decision Trees & Word2Vec):\")\n",
    "best_parameters = w2v_tree_model.best_estimator_.get_params()\n",
    "for param_name in sorted(tree_para.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
